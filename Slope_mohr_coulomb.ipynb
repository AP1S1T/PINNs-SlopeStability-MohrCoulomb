{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apisi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 2)  # Output 2 values: ux and uy\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Define the problem domain using vertices\n",
    "vertices = np.array([\n",
    "    [0, 0], [0, 3], [3, 3], [5, 2], [7, 2], [7, 0], [0, 0]\n",
    "], dtype=np.float32)\n",
    "path = Path(vertices)\n",
    "\n",
    "def in_domain(x, y):\n",
    "    points = np.column_stack((x.cpu().numpy(), y.cpu().numpy()))\n",
    "    return torch.tensor(path.contains_points(points), dtype=torch.bool, device=device)\n",
    "\n",
    "# Define boundary conditions\n",
    "def BC_bottom(x, y):\n",
    "    return ((y <= 0.1) & (x >= 0) & (x <= 7)).squeeze()\n",
    "\n",
    "def BC_left(x, y):\n",
    "    return ((x <= 0.1) & (y >= 0) & (y <= 3)).squeeze()\n",
    "\n",
    "def BC_top(x, y):\n",
    "    return (((y >= 2.9) & (x >= 0) & (x <= 3)) | \n",
    "            ((y - 4.5) * -2 == (x - 0)) & (x > 3) & (x < 5) |\n",
    "            (y == 2) & (x >= 5) & (x <= 7)).squeeze()\n",
    "\n",
    "def BC_right(x, y):\n",
    "    return ((x >= 6.9) & (y >= 0) & (y <= 2)).squeeze()\n",
    "\n",
    "\n",
    "def BC(xy, net):    \n",
    "    x, y = xy[:, 0], xy[:, 1]\n",
    "    \n",
    "    uv = net(xy)\n",
    "    u, v = uv[:, 0], uv[:, 1]\n",
    "    \n",
    "    bc_b = BC_bottom(x, y)     \n",
    "    bc_l = BC_left(x, y)\n",
    "    bc_t = BC_top(x, y)\n",
    "    bc_r = BC_right(x, y)\n",
    "    \n",
    "    E = 5  # <---------------Young's modulus\n",
    "    nu = 0.3  # <---------------Poisson's ratio\n",
    "    \n",
    "    loss = torch.mean(u[bc_b]**2 + v[bc_b]**2)  # ux = uy = 0 on bottom\n",
    "    \n",
    "    # Stress-free condition at the left (ux = 0, σxy = 0)\n",
    "    if torch.any(bc_l):\n",
    "        xy_left = xy[bc_l]\n",
    "        xy_left.requires_grad_(True)\n",
    "        uv_left = net(xy_left)\n",
    "        u_left, v_left = uv_left[:, 0], uv_left[:, 1]\n",
    "        \n",
    "        u_y_left = torch.autograd.grad(u_left.sum(), xy_left, create_graph=True)[0][:, 1]\n",
    "        v_x_left = torch.autograd.grad(v_left.sum(), xy_left, create_graph=True)[0][:, 0]\n",
    "        \n",
    "        sigma_xy_left = E / (2 * (1 + nu)) * (u_y_left + v_x_left)\n",
    "        loss += torch.mean(u_left**2 + sigma_xy_left**2)\n",
    "    \n",
    "    # Stress-free condition at the right (ux = 0, σxy = 0)\n",
    "    if torch.any(bc_r):\n",
    "        xy_right = xy[bc_r]\n",
    "        xy_right.requires_grad_(True)\n",
    "        uv_right = net(xy_right)\n",
    "        u_right, v_right = uv_right[:, 0], uv_right[:, 1]\n",
    "        \n",
    "        u_y_right = torch.autograd.grad(u_right.sum(), xy_right, create_graph=True)[0][:, 1]\n",
    "        v_x_right = torch.autograd.grad(v_right.sum(), xy_right, create_graph=True)[0][:, 0]\n",
    "        \n",
    "        sigma_xy_right = E / (2 * (1 + nu)) * (u_y_right + v_x_right)\n",
    "        loss += torch.mean(u_right**2 + sigma_xy_right**2)\n",
    "    \n",
    "    # Stress-free condition at the top (σxx = 0, σyy = 0, σxy = 0)\n",
    "    if torch.any(bc_t):\n",
    "        xy_top = xy[bc_t]\n",
    "        xy_top.requires_grad_(True)\n",
    "        uv_top = net(xy_top)\n",
    "        u_top, v_top = uv_top[:, 0], uv_top[:, 1]\n",
    "        \n",
    "        u_x_top = torch.autograd.grad(u_top.sum(), xy_top, create_graph=True)[0][:, 0]\n",
    "        u_y_top = torch.autograd.grad(u_top.sum(), xy_top, create_graph=True)[0][:, 1]\n",
    "        v_x_top = torch.autograd.grad(v_top.sum(), xy_top, create_graph=True)[0][:, 0]\n",
    "        v_y_top = torch.autograd.grad(v_top.sum(), xy_top, create_graph=True)[0][:, 1]\n",
    "        \n",
    "        sigma_xx_top = E / (1 - nu**2) * (u_x_top + nu * v_y_top)\n",
    "        sigma_yy_top = E / (1 - nu**2) * (v_y_top + nu * u_x_top)\n",
    "        sigma_xy_top = E / (2 * (1 + nu)) * (u_y_top + v_x_top)\n",
    "        loss += torch.mean(sigma_xx_top**2 + sigma_yy_top**2 + sigma_xy_top**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def load_fem_data(filename='FEM4_data.csv'): #ใช้ X,Y เป็น Reference Coordinate (Optional)\n",
    "    df = pd.read_csv(filename)\n",
    "    x = torch.tensor(df['X'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y = torch.tensor(df['Y'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    return x, y\n",
    "\n",
    "def generate_training_data(fem_data_file, n_boundary):\n",
    "    x, y = load_fem_data(fem_data_file)\n",
    "    \n",
    "    # points inside the domain\n",
    "    mask = in_domain(x, y)\n",
    "    x, y = x[mask].to(device), y[mask].to(device)\n",
    "    \n",
    "    # Generate boundary points\n",
    "    t = torch.linspace(0, 1, n_boundary, device=device).unsqueeze(1)\n",
    "    \n",
    "    # Define the boundary segments (สร้างจุด)\n",
    "    segments = [\n",
    "        ([0, 0, 0], [0, 3, 3]),  # Left boundary\n",
    "        ([0, 3, 5, 7, 7], [3, 3, 2, 2, 0]),  # Top and right boundary\n",
    "        ([7, 0], [0, 0])  # Bottom boundary\n",
    "    ]\n",
    "    \n",
    "    x_b = []\n",
    "    y_b = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        x_seg = torch.tensor(np.interp(t.cpu().numpy(), np.linspace(0, 1, len(segment[0])), segment[0]), dtype=torch.float32, device=device)\n",
    "        y_seg = torch.tensor(np.interp(t.cpu().numpy(), np.linspace(0, 1, len(segment[1])), segment[1]), dtype=torch.float32, device=device)\n",
    "        x_b.append(x_seg)\n",
    "        y_b.append(y_seg)\n",
    "    \n",
    "    x_b = torch.cat(x_b)\n",
    "    y_b = torch.cat(y_b)\n",
    "    \n",
    "    return x.to(device), y.to(device), x_b.to(device), y_b.to(device)\n",
    "\n",
    "#Define Tension cut off function\n",
    "def tension_cutoff_yield_functions(sigma_1, sigma_2, sigma_3, sigma_t):\n",
    "    f4 = sigma_1 - sigma_t\n",
    "    f5 = sigma_2 - sigma_t\n",
    "    f6 = sigma_3 - sigma_t\n",
    "    return torch.stack([f4, f5, f6], dim=-1)\n",
    "#Define Mohr coulomb yield function\n",
    "def mohr_coulomb_yield_functions(sigma_1, sigma_2, sigma_3, c, phi, sigma_t):\n",
    "    sin_phi = torch.sin(phi)\n",
    "    cos_phi = torch.cos(phi)\n",
    "\n",
    "    f1a = 0.5 * (sigma_2 - sigma_3) + 0.5 * (sigma_2 + sigma_3) * sin_phi - c * cos_phi\n",
    "    f1b = 0.5 * (sigma_3 - sigma_2) + 0.5 * (sigma_3 + sigma_2) * sin_phi - c * cos_phi\n",
    "    f2a = 0.5 * (sigma_3 - sigma_1) + 0.5 * (sigma_3 + sigma_1) * sin_phi - c * cos_phi\n",
    "    f2b = 0.5 * (sigma_1 - sigma_3) + 0.5 * (sigma_1 + sigma_3) * sin_phi - c * cos_phi\n",
    "    f3a = 0.5 * (sigma_1 - sigma_2) + 0.5 * (sigma_1 + sigma_2) * sin_phi - c * cos_phi\n",
    "    f3b = 0.5 * (sigma_2 - sigma_1) + 0.5 * (sigma_2 + sigma_1) * sin_phi - c * cos_phi\n",
    "\n",
    "    f_mc = torch.stack([f1a, f1b, f2a, f2b, f3a, f3b], dim=-1)\n",
    "    \n",
    "    f_tension = tension_cutoff_yield_functions(sigma_1, sigma_2, sigma_3, sigma_t)\n",
    "    \n",
    "    yield_values = torch.cat([f_mc, f_tension], dim=-1)\n",
    "    return yield_values, torch.max(yield_values, dim=-1)[0]\n",
    "#Define plastic potential\n",
    "def plastic_potential(sigma_1, sigma_2, sigma_3, psi):\n",
    "    sin_psi = torch.sin(psi)\n",
    "    g1a = 0.5 * (sigma_2 - sigma_3) + 0.5 * (sigma_2 + sigma_3) * sin_psi\n",
    "    g1b = 0.5 * (sigma_3 - sigma_2) + 0.5 * (sigma_3 + sigma_2) * sin_psi\n",
    "    g2a = 0.5 * (sigma_3 - sigma_1) + 0.5 * (sigma_3 + sigma_1) * sin_psi\n",
    "    g2b = 0.5 * (sigma_1 - sigma_3) + 0.5 * (sigma_1 + sigma_3) * sin_psi\n",
    "    g3a = 0.5 * (sigma_1 - sigma_2) + 0.5 * (sigma_1 + sigma_2) * sin_psi\n",
    "    g3b = 0.5 * (sigma_2 - sigma_1) + 0.5 * (sigma_2 + sigma_1) * sin_psi\n",
    "    return torch.stack([g1a, g1b, g2a, g2b, g3a, g3b], dim=-1)\n",
    "    \n",
    "#Define Elastic matrix\n",
    "def calculate_D_e(E, nu, device):\n",
    "    D_e = E / ((1 + nu) * (1 - 2*nu)) * torch.tensor([\n",
    "        [1-nu, nu, 0],\n",
    "        [nu, 1-nu, 0],\n",
    "        [0, 0, (1-2*nu)/2]\n",
    "    ], device=device)\n",
    "    return D_e\n",
    "\n",
    "def calculate_D_ep(D, r, df_dsigma, df_dxi, h):\n",
    "    D_r = torch.einsum('bij,bj->bi', D, r)\n",
    "    numerator = torch.einsum('bi,bj->bij', D_r, torch.einsum('bij,bj->bi', D, df_dsigma))  \n",
    "    \n",
    "    denominator = torch.einsum('bi,bij,bj->b', df_dsigma, D, r) - torch.einsum('bi,bi->b', df_dxi, h)\n",
    "    denominator = torch.clamp(denominator, min=1e-8) #Prevent division by zero\n",
    "    \n",
    "    D_ep = D - numerator / denominator.unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    return D_ep\n",
    "\n",
    "#Define principal stress calculation\n",
    "def calculate_principal_stresses(sigma_xx, sigma_yy, sigma_xy):\n",
    "    # คำนวณค่าเค้นหลัก\n",
    "    sigma_avg = (sigma_xx + sigma_yy) / 2\n",
    "    R = torch.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + sigma_xy ** 2)\n",
    "\n",
    "    sigma_1 = sigma_avg + R  # ค่าเค้นหลักที่มากที่สุด (Maximum principal stress)\n",
    "    sigma_3 = sigma_avg - R  # ค่าเค้นหลักที่น้อยที่สุด (Minimum principal stress)\n",
    "    return sigma_1, sigma_3\n",
    "\n",
    "def PDE(x, y, net):\n",
    "    device = x.device\n",
    "    xy = torch.cat([x, y], dim=1)\n",
    "    xy.requires_grad = True\n",
    "    \n",
    "    uv = net(xy)\n",
    "    u, v = uv[:, 0].unsqueeze(1), uv[:, 1].unsqueeze(1)\n",
    "    \n",
    "    u_x = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    u_y = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    v_x = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    v_y = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    \n",
    "    # Material properties\n",
    "    E = torch.tensor(5.0, device=device)  # <--------------- Young's modulus \n",
    "    nu = torch.tensor(0.3, device=device)  # <---------------Poisson's ratio\n",
    "    gamma = torch.tensor(1.8, device=device)  # <---------------Unit weight\n",
    "    c = torch.tensor(3, device=device)  # <---------------Cohesion\n",
    "    phi = torch.tensor(13, device=device)  # <---------------Friction angle in degrees\n",
    "    psi = torch.tensor(0.0, device=device)  # <---------------Dilation angle in degrees\n",
    "    sigma_t = torch.tensor(0.0, device=device)  # <---------------Tension cut-off\n",
    "\n",
    "    D_e = calculate_D_e(E, nu, device)\n",
    "    D_e = D_e.unsqueeze(0).expand(x.size(0), -1, -1)\n",
    "\n",
    "    strain = torch.stack([u_x, v_y, u_y + v_x], dim=-1).squeeze(-2)\n",
    "    sigma_e = torch.einsum('bij,bj->bi', D_e, strain)\n",
    "    sigma_xx, sigma_yy, sigma_xy = sigma_e.unbind(dim=-1)\n",
    "\n",
    "    sigma_1, sigma_3 = calculate_principal_stresses(sigma_xx, sigma_yy, sigma_xy)\n",
    "    sigma_2 = torch.zeros_like(sigma_1)\n",
    "    \n",
    "    yield_values, max_yield = mohr_coulomb_yield_functions(sigma_1, sigma_2, sigma_3, c, phi, sigma_t)\n",
    "    potential_values = plastic_potential(sigma_1, sigma_2, sigma_3, psi)\n",
    "    \n",
    "    df_dsigma = torch.autograd.grad(yield_values.sum(), sigma_e, create_graph=True)[0]\n",
    "    dg_dsigma = torch.autograd.grad(potential_values.sum(), sigma_e, create_graph=True)[0]\n",
    "    \n",
    "    \n",
    "    df_dxi = torch.zeros_like(df_dsigma[:, :1])\n",
    "    h = torch.zeros_like(df_dxi)\n",
    "    \n",
    "    D_ep = calculate_D_ep(D_e, dg_dsigma, df_dsigma, df_dxi, h)\n",
    "    \n",
    "    # Plastic strain increment\n",
    "    lambda_p = torch.where(max_yield > 0, \n",
    "                        1 / (torch.einsum('bi,bij,bj->b', df_dsigma, D_e, dg_dsigma) + 1e-8),\n",
    "                        torch.zeros_like(max_yield))\n",
    "    d_epsilon_p = lambda_p.unsqueeze(-1) * dg_dsigma\n",
    "    \n",
    "    #Total strain\n",
    "    epsilon_total = strain + d_epsilon_p\n",
    "    \n",
    "    #Stress correction using D_ep\n",
    "    sigma_corrected = torch.einsum('bij,bj->bi', D_ep, epsilon_total)\n",
    "\n",
    "    sigma_xx_corrected, sigma_yy_corrected, sigma_xy_corrected = sigma_corrected.unbind(dim=-1)\n",
    "\n",
    "    f_x = torch.zeros_like(x)\n",
    "    f_y = -gamma * torch.ones_like(y)\n",
    "\n",
    "    R_x = torch.autograd.grad(sigma_xx_corrected.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1) + \\\n",
    "          torch.autograd.grad(sigma_xy_corrected.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1) + f_x\n",
    "    R_y = torch.autograd.grad(sigma_xy_corrected.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1) + \\\n",
    "          torch.autograd.grad(sigma_yy_corrected.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1) + f_y\n",
    "\n",
    "    yield_loss = torch.mean(torch.relu(max_yield))\n",
    "    potential_loss = torch.mean(torch.abs(potential_values))\n",
    "    pde_loss_x = torch.mean(R_x ** 2)\n",
    "    pde_loss_y = torch.mean(R_y ** 2)\n",
    "\n",
    "    return pde_loss_x, pde_loss_y, yield_loss, potential_loss, sigma_corrected, epsilon_total\n",
    "\n",
    "def phi_c_reduction(net, fem_data_file, initial_sf=1.0, sf_step=0.01, max_iterations=1000):\n",
    "    device = next(net.parameters()).device\n",
    "    \n",
    "    c_initial = torch.tensor(3.0, device=device)\n",
    "    phi_initial = torch.deg2rad(torch.tensor(13.0, device=device))\n",
    "    \n",
    "    current_sf = initial_sf\n",
    "    \n",
    "    x, y, x_b, y_b = generate_training_data(fem_data_file, 30000)\n",
    "    xy = torch.cat([x, y], dim=1).requires_grad_(True)\n",
    "    \n",
    "    sf_values = []\n",
    "    failure_ratios = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        c_reduced = c_initial / current_sf\n",
    "        phi_reduced = torch.atan(torch.tan(phi_initial) / current_sf)\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            uv = net(xy)\n",
    "            u, v = uv[:, 0], uv[:, 1]\n",
    "            \n",
    "            u_x = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 0]\n",
    "            u_y = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 1]\n",
    "            v_x = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 0]\n",
    "            v_y = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 1]\n",
    "            \n",
    "            E = torch.tensor(5.0, device=device) #<--------------- Young's modulus\n",
    "            nu = torch.tensor(0.3, device=device) #<--------------- Poisson's ratio\n",
    "            \n",
    "            D_e = calculate_D_e(E, nu, device)\n",
    "            D_e = D_e.unsqueeze(0).expand(x.size(0), -1, -1)\n",
    "            \n",
    "            strain = torch.stack([u_x, v_y, u_y + v_x], dim=-1)\n",
    "            sigma_e = torch.einsum('bij,bj->bi', D_e, strain)\n",
    "            sigma_xx, sigma_yy, sigma_xy = sigma_e.unbind(dim=-1)\n",
    "            \n",
    "            sigma_1, sigma_3 = calculate_principal_stresses(sigma_xx, sigma_yy, sigma_xy)\n",
    "        \n",
    "        # Using Mohr-Coulomb criterion with reduced strength parameters\n",
    "        failure_criterion = (sigma_1 - sigma_3) - (sigma_1 + sigma_3) * torch.sin(phi_reduced) - 2 * c_reduced * torch.cos(phi_reduced)\n",
    "        \n",
    "        failure_ratio = torch.sum(failure_criterion > 0) / failure_criterion.numel()\n",
    "        sf_values.append(current_sf)\n",
    "        failure_ratios.append(failure_ratio.item())\n",
    "        \n",
    "        if failure_ratio > 0.01:  # If more than 1% of points fail\n",
    "            return current_sf, sf_values, failure_ratios\n",
    "        \n",
    "        current_sf += sf_step\n",
    "    \n",
    "    return current_sf, sf_values, failure_ratios\n",
    "\n",
    "def train(net, optimizer, n_epochs, fem_data_file):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=500, verbose=True)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x, y, x_b, y_b = generate_training_data(fem_data_file, 30000)  # 30000 data points\n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        xy_b = torch.cat([x_b, y_b], dim=1)\n",
    "        \n",
    "        pde_results = PDE(x, y, net)\n",
    "        loss_pde_x, loss_pde_y, yield_loss, potential_loss = pde_results[:4]\n",
    "        loss_bc = BC(xy_b, net)\n",
    "        \n",
    "        loss = loss_pde_x + 2 * loss_pde_y + loss_bc + 0.1 * yield_loss + 0.1 * potential_loss\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            print(f\"NaN loss detected at epoch {epoch+1}\")\n",
    "            print(f\"loss_pde_x: {loss_pde_x.item()}, loss_pde_y: {loss_pde_y.item()}\")\n",
    "            print(f\"loss_bc: {loss_bc.item()}, yield_loss: {yield_loss.item()}\")\n",
    "            print(f\"potential_loss: {potential_loss.item()}\")\n",
    "            break\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save({\n",
    "                'net_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, 'best_model.pth')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Total Loss: {loss.item():.6f}, '\n",
    "                  f'PDE Loss X: {loss_pde_x.item():.6f}, PDE Loss Y: {loss_pde_y.item():.6f}, '\n",
    "                  f'BC Loss: {loss_bc.item():.6f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "            \n",
    "def calculate_elastic_plastic_status(sigma_1, sigma_3, c, phi, sigma_yy, sigma_xx,sigma_xy):\n",
    "    sin_phi = torch.sin(torch.deg2rad(phi))\n",
    "    cos_phi = torch.cos(torch.deg2rad(phi))\n",
    "    c = 3  # <--------------Cohesion\n",
    "    phi = torch.tensor(13, device=sigma_1.device, dtype=sigma_1.dtype) #<--------------friction angle\n",
    "    sigma_avg = (sigma_xx + sigma_yy) / 2\n",
    "    R = torch.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + sigma_xy ** 2)\n",
    "\n",
    "    sigma_1 = (sigma_avg + R)*10  # ค่าเค้นหลักที่มากที่สุด (Maximum principal stress)\n",
    "    sigma_3 = (sigma_avg - R)*10  # ค่าเค้นหลักที่น้อยที่สุด (Minimum principal stress)\n",
    "\n",
    "    # Calculate τmob (mobilized shear strength)\n",
    "    tau_mob = (sigma_1 - sigma_3) / 2\n",
    "    \n",
    "    # Calculate τmax (maximum shear strength)\n",
    "    tau_max = c * cos_phi - ((sigma_1 + sigma_3) / 2) * sin_phi\n",
    "    \n",
    "    # Calculate τrel (relative shear strength)\n",
    "    tau_rel = torch.abs(tau_mob / tau_max)\n",
    "    \n",
    "    # Define tolerance for considering status\n",
    "    tolerance = 0.99\n",
    "    \n",
    "    # 0: Elastic, 1: Plastic (Failure)\n",
    "    status = torch.where(tau_rel > tolerance, torch.ones_like(tau_rel), torch.zeros_like(tau_rel))\n",
    "    \n",
    "    return status, tau_rel, tau_max, tau_mob\n",
    "\n",
    "\n",
    "def plot_results(net, fem_data_file='FEM4_data.csv', output_filename='PiNN4_data.csv'):\n",
    "    df_fem = pd.read_csv(fem_data_file)\n",
    "    X = df_fem['X'].values\n",
    "    Y = df_fem['Y'].values\n",
    "    \n",
    "    XY = torch.tensor(np.column_stack([X, Y]), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        UV = net(XY)\n",
    "        U, V = UV[:, 0], UV[:, 1]\n",
    "        \n",
    "        U_x = torch.autograd.grad(U.sum(), XY, create_graph=True)[0][:, 0]\n",
    "        U_y = torch.autograd.grad(U.sum(), XY, create_graph=True)[0][:, 1]\n",
    "        V_x = torch.autograd.grad(V.sum(), XY, create_graph=True)[0][:, 0]\n",
    "        V_y = torch.autograd.grad(V.sum(), XY, create_graph=True)[0][:, 1]\n",
    "        \n",
    "        E = 5  # <--------------Young's modulus\n",
    "        nu = 0.3  # <--------------Poisson's ratio\n",
    "        c = 3  # <--------------Cohesion\n",
    "        phi = torch.deg2rad(torch.tensor(13.0, device=device))  # <--------------Friction angle\n",
    "        \n",
    "        # Calculate strain components\n",
    "        epsilon_xx = U_x\n",
    "        epsilon_yy = V_y\n",
    "        epsilon_xy = 0.5 * (U_y + V_x)\n",
    "\n",
    "        # Calculate principal strains\n",
    "        epsilon_avg = 0.5 * (epsilon_xx + epsilon_yy)\n",
    "        epsilon_diff = 0.5 * torch.sqrt((epsilon_xx - epsilon_yy)**2 + 4 * epsilon_xy**2)\n",
    "        epsilon_1 = epsilon_avg + epsilon_diff\n",
    "        epsilon_3 = epsilon_avg - epsilon_diff\n",
    "\n",
    "        # Calculate stress components\n",
    "        sigma_xx = E / (1 - nu**2) * (U_x + nu * V_y)\n",
    "        sigma_yy = E / (1 - nu**2) * (V_y + nu * U_x)\n",
    "        sigma_xy = E / (2 * (1 + nu)) * (U_y + V_x)\n",
    "        \n",
    "        # Calculate principal stresses\n",
    "        sigma_avg = (sigma_xx + sigma_yy) / 2\n",
    "        R = torch.sqrt(((sigma_xx - sigma_yy) / 2) ** 2 + sigma_xy ** 2)\n",
    "\n",
    "        sigma_1 = sigma_avg + R\n",
    "        sigma_3 = sigma_avg - R\n",
    "\n",
    "    # Detach tensors and move to CPU for numpy operations\n",
    "    with torch.no_grad():\n",
    "        sigma_1_full = sigma_1.cpu().numpy().squeeze() * 10\n",
    "        sigma_3_full = sigma_3.cpu().numpy().squeeze() * 10\n",
    "\n",
    "        # Initialize arrays for sorted stresses\n",
    "        sigma_1_sorted = np.zeros_like(sigma_1_full)\n",
    "        sigma_3_sorted = np.zeros_like(sigma_3_full)\n",
    "\n",
    "        # Sort stresses for each coordinate\n",
    "        for i in range(len(sigma_1_full)):\n",
    "            # Sort by absolute value\n",
    "            sorted_indices = np.argsort(np.abs([sigma_1_full[i], sigma_3_full[i]]))[::-1]\n",
    "            sigma_1_sorted[i] = -abs([sigma_1_full[i], sigma_3_full[i]][sorted_indices[0]])\n",
    "            sigma_3_sorted[i] = -abs([sigma_1_full[i], sigma_3_full[i]][sorted_indices[1]])\n",
    "        \n",
    "        c = 3  # <--------------Cohesion\n",
    "        phi = torch.tensor(13, device=sigma_1.device, dtype=sigma_1.dtype) #<-------------- Friction angle\n",
    "\n",
    "        status, tau_rel, tau_max, tau_mob = calculate_elastic_plastic_status(sigma_1, sigma_3, c, phi, sigma_yy, sigma_xx, sigma_xy)\n",
    "\n",
    "        status_full = status.cpu().numpy().squeeze()\n",
    "        tau_rel_full = tau_rel.cpu().numpy().squeeze()\n",
    "        tau_max_full = tau_max.cpu().numpy().squeeze()\n",
    "        tau_mob_full = tau_mob.cpu().numpy().squeeze()\n",
    "        U_full = U.cpu().numpy().squeeze() / 1000     \n",
    "        V_full = V.cpu().numpy().squeeze() / 1000\n",
    "        sigma_xx_full = sigma_xx.cpu().numpy().squeeze() * 10\n",
    "        sigma_yy_full = sigma_yy.cpu().numpy().squeeze() * 10\n",
    "        sigma_xy_full = sigma_xy.cpu().numpy().squeeze() * 10\n",
    "        epsilon_xx_full = epsilon_xx.cpu().numpy().squeeze()\n",
    "        epsilon_yy_full = epsilon_yy.cpu().numpy().squeeze()\n",
    "        epsilon_xy_full = epsilon_xy.cpu().numpy().squeeze()\n",
    "        epsilon_1_full = epsilon_1.cpu().numpy().squeeze()\n",
    "        epsilon_3_full = epsilon_3.cpu().numpy().squeeze()\n",
    "        magnitude = np.sqrt(U_full**2 + V_full**2)\n",
    "\n",
    "    # Calculate Safety Factor\n",
    "    sf, sf_values, failure_ratios = phi_c_reduction(net, fem_data_file)\n",
    "    print(f\"Calculated Safety Factor: {sf:.4f}\")\n",
    "    \n",
    "    df_out = pd.DataFrame({\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'ux': U_full,\n",
    "        'uy': V_full,\n",
    "        'sigma_xx': sigma_xx_full,\n",
    "        'sigma_yy': sigma_yy_full,\n",
    "        'sigma_xy': sigma_xy_full,\n",
    "        'sigma_1': sigma_1_sorted,\n",
    "        'sigma_3': sigma_3_sorted,\n",
    "        'epsilon_xx': epsilon_xx_full,\n",
    "        'epsilon_yy': epsilon_yy_full,\n",
    "        'epsilon_xy': epsilon_xy_full,\n",
    "        'epsilon_1': epsilon_1_full,\n",
    "        'epsilon_3': epsilon_3_full,\n",
    "        'magnitude': magnitude,\n",
    "        'status': status_full,\n",
    "        'strength_ratio': tau_rel_full,\n",
    "        'tau_max': tau_max_full,\n",
    "        'tau_mob': tau_mob_full,\n",
    "        'safety_factor': sf,\n",
    "    })\n",
    "\n",
    "    df_out.to_csv(output_filename, index=False)\n",
    "    print(f\"Results saved to {output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('PiNN_results.png')\n",
    "    plt.show()\n",
    "    return sf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    net = Net().to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    fem_data_file = 'FEM4_data.csv'\n",
    "    train(net, optimizer, n_epochs=1000, fem_data_file=fem_data_file)\n",
    "    \n",
    "    checkpoint = torch.load('best_model.pth', map_location=device)\n",
    "    net.load_state_dict(checkpoint['net_state_dict'])\n",
    "    \n",
    "    try:\n",
    "        sf = plot_results(net, fem_data_file=fem_data_file)\n",
    "        print(f\"\\nSafety Factor: {sf:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in plot_results: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
